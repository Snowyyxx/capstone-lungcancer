{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "716c2d13-0377-4371-b07c-b0356dffef56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 875, Train: 700, Test: 175\n",
      "Loading existing model from lung_cancer_model_epoch_10.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17034/2203943153.py:103: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "# **Preprocessing function for single image**\n",
    "def preprocess_ct_image(image_path):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "    ])\n",
    "    \n",
    "    image = Image.open(image_path).convert(\"L\")\n",
    "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "    return image\n",
    "\n",
    "# **Dataset Class**\n",
    "class LungDataset(Dataset):\n",
    "    def __init__(self, img_dir, mask_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.patients = sorted(os.listdir(img_dir))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patients)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        patient_id = self.patients[idx]\n",
    "        nodule_folder = os.path.join(self.img_dir, patient_id, \"nodule-0\")\n",
    "\n",
    "        image_path = os.path.join(nodule_folder, \"images\")\n",
    "        mask_paths = [os.path.join(nodule_folder, f\"mask-{i}\") for i in range(4)]\n",
    "\n",
    "        image_slices = sorted(os.listdir(image_path))\n",
    "        mask_slices = [sorted(os.listdir(mask_path)) for mask_path in mask_paths]\n",
    "\n",
    "        # Pick **middle slice** \n",
    "        mid_slice = len(image_slices) // 2  \n",
    "        img = Image.open(os.path.join(image_path, image_slices[mid_slice])).convert(\"L\")\n",
    "        img = self.transform(img) if self.transform else transforms.ToTensor()(img)\n",
    "\n",
    "        # Get and average masks\n",
    "        mask_stack = torch.stack([\n",
    "            transforms.ToTensor()(Image.open(os.path.join(mask_paths[j], mask_slices[j][mid_slice])).convert(\"L\"))\n",
    "            for j in range(4)\n",
    "        ])\n",
    "        avg_mask = mask_stack.mean(dim=0)  # Average masks\n",
    "        avg_mask = (avg_mask > 0.5).float()  # Binarize\n",
    "\n",
    "        return img, avg_mask\n",
    "\n",
    "\n",
    "# **Set base directory**\n",
    "base_dir = \"datasets/LIDC-IDRI-slices\"\n",
    "\n",
    "# **Transformations**\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "# **Load dataset**\n",
    "dataset = LungDataset(base_dir, base_dir, transform=transform)\n",
    "\n",
    "# **Split into train and test**\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "print(f\"Total images: {len(dataset)}, Train: {len(train_dataset)}, Test: {len(test_dataset)}\")\n",
    "\n",
    "# **Define U-Net Model with ResNet34 Backbone**\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = smp.Unet(encoder_name=\"resnet34\", encoder_weights=\"imagenet\", in_channels=1, classes=1).to(device)\n",
    "\n",
    "# **Define Loss Function & Optimizer**\n",
    "def dice_loss(pred, target, smooth=1.):\n",
    "    pred = torch.sigmoid(pred)  \n",
    "    intersection = (pred * target).sum()\n",
    "    return 1 - ((2. * intersection + smooth) / (pred.sum() + target.sum() + smooth))\n",
    "\n",
    "criterion = dice_loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# **Model Saving & Loading**\n",
    "num_epochs = 10\n",
    "checkpoint_path = f\"lung_cancer_model_epoch_{num_epochs}.pth\"\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(f\"Loading existing model from {checkpoint_path}\")\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "else:\n",
    "    # **Training Loop**\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for images, masks in train_loader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # Save Model\n",
    "    torch.save(model.state_dict(), checkpoint_path)\n",
    "    print(f\"Model saved as {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f90978b8-8c9e-42c7-9081-838e34e8eceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dice Score: 0.7841\n",
      "Test IoU: 0.6480\n",
      "Test Accuracy: 0.9982\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# **Testing Loop**\n",
    "model.eval()\n",
    "test_dice_score = 0\n",
    "test_iou = 0\n",
    "test_acc = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, masks in test_loader:\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = torch.sigmoid(outputs) > 0.5  \n",
    "\n",
    "        # Compute Dice Score\n",
    "        intersection = (preds * masks).sum()\n",
    "        dice_score = (2. * intersection) / (preds.sum() + masks.sum() + 1e-8)\n",
    "\n",
    "        # Compute IoU\n",
    "        iou = intersection / (preds.sum() + masks.sum() - intersection + 1e-8)\n",
    "\n",
    "        # Compute Accuracy\n",
    "        acc = (preds == masks).float().mean()\n",
    "\n",
    "        test_dice_score += dice_score.item()\n",
    "        test_iou += iou.item()\n",
    "        test_acc += acc.item()\n",
    "\n",
    "print(f\"Test Dice Score: {test_dice_score/len(test_loader):.4f}\")\n",
    "print(f\"Test IoU: {test_iou/len(test_loader):.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc/len(test_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5dd0b30b-874e-4ec8-ad50-d3e0f673e887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Tumor Probability: 0.0404\n",
      "Predicted Tumor Size (in pixels): 618\n",
      "Predicted Cancer Stage: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# **Prediction Function with Tumor Size Calculation**\n",
    "def predict_cancer_stage(image_path, model, device):\n",
    "    model.eval()\n",
    "    image = preprocess_ct_image(image_path).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        output = torch.sigmoid(output)  \n",
    "        tumor_mask = output > 0.5  \n",
    "\n",
    "        tumor_size = tumor_mask.sum().item()  \n",
    "        tumor_prob = output.mean().item()  \n",
    "\n",
    "    # **Determine Cancer Stage**\n",
    "    STAGE_THRESHOLDS = {0: 0.0, 1: 0.2, 2: 0.5, 3: 0.8}\n",
    "    predicted_stage = max([stage for stage, threshold in STAGE_THRESHOLDS.items() if tumor_prob > threshold])\n",
    "\n",
    "    print(f\"Predicted Tumor Probability: {tumor_prob:.4f}\")\n",
    "    print(f\"Predicted Tumor Size (in pixels): {tumor_size}\")\n",
    "    print(f\"Predicted Cancer Stage: {predicted_stage}\")\n",
    "    \n",
    "    return predicted_stage, tumor_size\n",
    "\n",
    "# **Example Usage**\n",
    "#image_path = \"datasets/LIDC-IDRI-slices/LIDC-IDRI-0265/nodule-0/images/slice-3.png\"\n",
    "image_path = \"testimages/1.jpg\"\n",
    "predicted_stage, tumor_size = predict_cancer_stage(image_path, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7433b05a-d080-4b2f-876e-942f93f4d6ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
